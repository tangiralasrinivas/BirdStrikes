# Bird Strikes

### Project Overview

The collision of birds and planes is a rare event on a relative basis but one which may have catastrophic consequences, as some highly publicized examples, such as ‚ÄúThe Miracle on the Hudson,‚Äù demonstrate. It is not possible to mitigate the risk of a strike per se, because it is not possible for pilots to dodge birds in flight. Yet, awareness of the relative level of risk at pre-flight and descent planning stages can mitigate the severity of the potential outcomes as the discussion of the risk, and the steps each crew member will take if the event occurs, will save precious time should there be an emergency such as engine failure or other severe damage.

This project aims to develop a predictive model to assess strike risk, and a tool through which this information can be made available to pilots and other interested parties in an easy-to-use manner. Our work focused on Denver International Airport in the first instance, but the insights and knowledge developed through our analyses and models are readily generalizable to all airfields in the continental United States. We developed a predictive model which assesses the daily level of strike risk based on public data sourced from the Federal Aviation Administration (FAA), National Oceanic and Administrative Administration (NOAA), and eBirds database maintained by The Cornell Lab of Ornithology.

Our approach to the development of the final model is grounded in primary research and a conceptual framework which we developed based on this research. It describes the causal relationships which ultimately lead to a bird strike, and therefore, describe strike risk. Our findings indicate these relationships are nonlinear and, with the data available, comparatively weak, which necessitated the use of non-parametric models for the prediction task. Moreover, we analyzed radar-derived estimates of bird mass and found the spatial and temporal scale at which the analyses are conducted matter greatly, with significantly strong relationships evident the closer one can move, in time and space, to the historic strike event. These conclusions accord with intuition, are consistent with the aforementioned conceptual framework, and provide a clear path forward for the refinement of the model to provide risk assessments at on hourly or even near-time basis for all airports in the U.S.

It is our intention to continue our engagement with commercial airlines and the FAA upon completion of the program, and it is our hope that the usage of a tool, such as ours, as well as the discussion of bird strike risk as part of every pre-flight briefing, will eventually become obligatory.

### Business Assumptions
It was necessary from the onset to state business assumptions that narrow our focus to analyze the correct data. To this extent, we determined the top four airports in the US with the most bird strikes between 2000 ‚Äì 2019 as Denver International Airport (KDEN) at 2,814 strikes, Dallas Fort Worth International (KDFW) at 2,170 strikes, Sacramento International (KSMF) at 1,891 strikes, and Chicago O‚ÄôHare International (KORD) at 1,557 strikes. We focused on one airfield, Denver International Airfield (KDEN), for the development of the initial model before evaluating additional airfields, where we intend to fit similar models as the one chosen for Denver in the future. We restricted our data as follows:

1. We included only bird strikes where the strike occurred with a commercial airplane.
2. We included only bird strikes where the strike occurred at or below 2,000 feet above ground level (AGL).
Using bird strikes at this low altitude ensures the strike actually occurred within 10 nautical miles of Denver International Airport (KDEN). Bird strikes above 2,000 feet AGL will vary in distance from KDEN, and we can no longer say, with confidence, that the bird strike occurred at KDEN and during the most critical and risky phase of the flight.
3. We included only bird strikes in our analysis. All other wildlife aircraft strikes were dropped.
4. Given concerns about recording practices prior to 2000, we excluded this time period and focused our
analysis on the years 2000 ‚Äì 2019.

### Problem Statement
Bird strikes, the act of a bird striking an airplane, are an inherent risk to aviation. As a result of this risk, the Federal Aviation Administration (FAA) has developed a database to document all of the reported bird strikes from 1990 to present day. Since this program‚Äôs inception, the Wildlife Strike Database has shown a steady increase in the number of reported strikes from approximately 1,800 strikes in 1990 to over 16,000 strikes in 2018. (Federal Aviation Administration, U.S. Department of Transportation, 2020). There are several contributing factors to this growth, which we expect to continue, and even occur more frequently in the future. These are:

1. A rise in large bird population coupled with their increasing ability to habituate urban environments, such as airports.
2. Continued growth in the civil aviation industry (Pre COVID-19), driven by passenger demand and leading to higher flight counts.
3. Upgrades in aircraft technology that yield faster aircraft and quieter aircraft engines; as a result, it is harder for birds to detect the aircraft and avoid it.

### Model Development and Evaluation
A key choice to make in any modeling task is the selection or definition of the variable of interest, and a well-chosen (or well-constructed) target variable can ultimately lead to better (more accurate and/or more intuitive) models. Our first inclination in approaching this project was to model the number of bird strikes directly by way of an investigation of how various plausible covariates influence these quantities.
As alluded to in the Business Objective, our view from the outset was that we would need to give air crews a risk rating, i.e. a measure of risk on a scale with a limited number of steps as our business understanding indicates that this would be more intuitive than an absolute measure. The risk of experiencing a bird strike in absolute terms is always comparatively low (on the order of 4bps per hour for Denver), and industry conversations indicated that this is not an intuitive quantity for most pilots, whereas a rating scale which would position, for example, a medium rating being twice as risky as a low rating, would be (provided the scale was otherwise well constructed and calibrated).


As set out in the introduction to this section, our initial attempts were aimed at predicting the number of strikes or the probability of a strike directly. To this end, we fitted and evaluated several different count regression models, as well as logistic regressions with either the number of strikes or the probability of a strike as the target variable, and the weather variables as our regressors. This was based on our initial EDA and variable selection analyses, we experimented with several lags of the variables on the hypothesis that there may be a delay in how these variables affect bird behavior. The final regression models comprised 13 independent variables and strike count or strike chance was our target variable.

This labeled data set served as the basis for a second wave of models, which were simply binary classification models that predicted whether or not a strike occurred. It‚Äôs important to note that the failure of the non-parametric ‚Äúregression‚Äù models (discussed above) to yield good point estimates, led us to think about why the underlying relationships, although well documented, appeared to be so weak in our data set. 
We conclude that behavior needs to be modeled at a lower level of temporal and spatial granularity. We fitted and evaluated a wide range of models based on the daily data set, with the variables. For all of the models we employed a 5-fold cross validation approach with 30% of the data retained as a test set. Since the data set was fairly unbalanced, we employed up and down sampling approaches, as well as the creation of synthetic data points via the SMOTE technique before feeding the data into the models. The results from the first set of untuned models are given in Table 8 - Binary Classification, Non-Parametric Model Evaluation. While the Accuracy and results of these classification models were insightful, the binary output (strike yes or strike no) did not map clearly to our strike risk scale defined in the previous section. As a result, we continued to explore other models where the output could be mapped to strike risk and clearly relayed the message to aircrews.

Following the fitting of the base models, we began to tune the models, both manually as well as through the H2O AutoML library. To this end, it is necessary to determine what the primary performance objective of the model should be, i.e. how one should trade-off overall accuracy with class-specific criteria, which we discuss in the next section.

### Model Selection
After the classification models failed to map to a comprehensible risk level, we shifted our analysis to developing a model that would predict the risk level itself. In order to do this, we had to develop a multi-class (3) classification model. Essentially, we utilized the risk scale discussed in the previous section to create High, Medium and Low risk classification labels that we then trained our model on. This allowed us to develop a multi-class (3) classification model that predicted the risk level itself and completely alleviated the need for our team map the probability of a strike or the total number of strikes to risk.
The final equation for the multi-class (3) classification model is below:

**RISK = ùõÉ0 + ùõÉ1 BIRDCOUNT + ùõÉ2 TEMP + ùõÉ3 MXSPD + ùõÉ4 PRECP+ ùõÉ5 FOG + ùõÉ6 RAIN_DRIZZLE + ùõÉ7 THUNDER + ùõÉ8 HAIL + ùõÉ9 WEEK +ùõÉ10 VISIB + ùõÉùõÇi +ùêûi**

Now, with a working multi nominal model framework, we then began to tune the models, both manually as well as through the H2O AutoML/Caret Tuning library. In order to successfully tune the model, it is necessary to determine what the primary performance objective of the model should be, i.e. how one should trade-off overall accuracy with class- specific criteria, which we discuss in the next section.


#### Tuning Objectives
In the context of bird strikes, over-estimating strike risk, that is to misclassify, a High risk day as a Low or Medium Risk day, is much more acceptable than under estimating risk. In other words, a Type II error (false negative) may have much more severe consequences than a false positive, generally speaking, as the latter only implies that the aircrew briefed for a situation which did not occur, while the former may mean the absence of preparation.

Naturally, this needs to be considered by class because misclassification for Low and High risk days can only go one way. We considered this extensively from a business perspective and ultimately settled on the following prioritization method for model performance.
When determining the best fit model, we based our selection on the following priorities: the highest Sensitivity value for the High class, ensuring very few false negative values. Next, we focused on the highest Specificity value for the Low class, ensuring very few false positive values. Lastly, we prioritized the highest Kappa value for the model that met our Sensitivity and Specificity requirements; the Kappa value measures the inter-rater reliability and essentially represents the extent to which the data collected is an accurate representation of the variables measured.

Our approach and model selection ensures we are predicting accurately in both the ‚ÄúH‚Äù and ‚ÄúL‚Äù class, which are the most critical risk classes for the aircrews. Further explanation of our rationale for both the ‚ÄúH‚Äù and ‚ÄúL‚Äù risk classes:

‚Ä¢ **High Risk Class** - If a strike risk of ‚ÄúH‚Äù is inaccurately predicted as not belonging in the ‚ÄúH‚Äù risk class (False Negative), then this result could be catastrophic for the flight because the aircrew would be under prepared for the true High risk scenario. The aircrew would view the threat of a bird strike as low or medium and as a result, they may not discuss or perform precautionary measures required for the true ‚ÄúH‚Äù risk. It is this business understanding that drove our team to focus on increasing Sensitivity in the ‚ÄúH‚Äù class, which mitigates false negatives when predicting the ‚ÄúH‚Äù class. On the other hand, False positives in the ‚ÄúH‚Äù class, are acceptable for us because in this scenario we are providing the aircrews with a more conservative risk value, ‚ÄúH‚Äù, then they would be actually facing.

‚Ä¢ **Low Risk Class** - If a strike risk of ‚ÄúL‚Äù is inaccurately predicted as belonging to the ‚ÄúL‚Äù risk class (False Positive), then this result would also under represent the threat to the aircrews, causing them to be under prepared for the actual ‚ÄúM‚Äù or ‚ÄúH‚Äù strike risk. Again, the aircrew would view the threat of a bird strike as low and therefore would not discuss or perform precautionary measures for the higher, true risk level. It is this business understanding that drove our team to focus on increasing Specificity in the ‚ÄúL‚Äù class, which mitigates false positives when predicting the ‚ÄúL‚Äù class. On the other hand, False negatives in the ‚ÄúL‚Äù class, are acceptable for us because in this scenario we are providing the aircrews with a more conservative risk value, ‚ÄúM‚Äù or ‚ÄúH‚Äù, which is higher than the risk they would be actually facing.


#### Model Training and Tuning
Based on the above considerations, we tuned several of the models before carrying out our final selection. Below, we discuss this work by way of an example for the XGBoost model.

##### Generalization Performance
To ensure that the models did not overfit the data, we employed 5-fold cross-validation during the fitting procedure, and evaluated fitting graphs for various sample sizes. It is evident that the error rates decline with larger amounts of data, as might be expected, but pleasingly we do not see a divergence across training and test data as the training sample grows. Therefore, we conclude that this model can be expected to generalize well.

##### Hyperparameter Tuning
Furthermore, we used hyperparameter tuning (with parameters differing across the model types) by varying the respective parameters for each model and evaluating the resulting performance for each run. We used a tuning parameter grid for the number of boosting iterations (nrounds), learning rate (eta) and the maximum depth of the trees (max_depth) for XGBoost with down sampled data.

### Final Model Selection
Based on the evaluation criteria defined above, the methods applied on the model selection and hyperparameter tuning, we ranked and shortlisted our models‚Äô results in Table 2 ‚Äì Multi-class (3) Classification Model, Non- Parametric Model Evaluation. With our prime focus on Sensitivity in the High class and Specificity in the Low class, we selected a model which performs moderately on the Medium class, reducing the overall accuracy of the model. This may seem counter-intuitive by the standards of most modeling work, but it is our view that the prioritizing performance in different classes in this differentiated manner is appropriate from a business application perspective.
Table 2 ‚Äì Multi-class (3) Classification Model, Non-Parametric Model , below, illustrates the best performing models of 16 total developed using Up/Down/Smote sampling on XGBoost, Elastic Net, Random Forest and GBM. The best model XGBoost (On Down sampled data) has the combination of high Sensitivity value in the High class at 76% with high Specificity value in the Low class at 79% and a fair agreement on the Kappa value at 31%. The learners used are computationally efficient and provide a good predictability with greater confidence.